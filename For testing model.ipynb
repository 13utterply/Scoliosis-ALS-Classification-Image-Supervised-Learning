{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f964814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE FILE PATH IN THIS CHUNK AND RUN THEM ALL ###\n",
    "# Load the model from the HDF5 file\n",
    "best_IncV3 = load_model(\"/path/to/load/Model.h5\")\n",
    "best_Xcep = load_model(\"/path/to/load/Model.h5\")\n",
    "best_ResNet50 = load_model(\"/path/to/load/Model.h5\")\n",
    "best_ResNet101 = load_model(\"/path/to/load/Model.h5\")\n",
    "\n",
    "\n",
    "#To prepare the test set, please make sure to label each image file with its respective class. \n",
    "#For instance, change the filename of each image as 'typeALS_OldName'. Use an underscore between 'typeALS' and 'OldName'. \n",
    "#For example, '3CH_image1.jpg'. \n",
    "#The image file can have different file extensions such as '.jpg', '.jpeg', '.png', '.gif', '.bmp', or '.tiff'.\n",
    "\n",
    "path_TESTSET = \"/path/to/load/image_fie/or/image_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_testset(directory, label_mapping):\n",
    "    # Function to load images using PIL\n",
    "    def load_images_from_directory_PIL(directory):\n",
    "        image_list = []\n",
    "        if not os.path.exists(directory):\n",
    "            print(f\"The directory '{directory}' does not exist.\")\n",
    "            return image_list\n",
    "        \n",
    "        image_files = [f for f in os.listdir(directory) if f.lower().endswith(('JPG', 'JPEG', '.jpg', '.png', '.jpeg', '.gif', '.bmp', '.tiff'))]\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(directory, image_file)\n",
    "            try:\n",
    "                img = Image.open(image_path)\n",
    "                image_list.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening image {image_path}: {e}\")\n",
    "        return image_list\n",
    "    \n",
    "    # Function to convert PIL images to pixel arrays\n",
    "    def convert_images_to_arrays(image_list):\n",
    "        pixel_arrays = []\n",
    "        for img in image_list:\n",
    "            img_array = np.array(img)\n",
    "            pixel_arrays.append(img_array)\n",
    "        return pixel_arrays\n",
    "    \n",
    "    # Function to extract filename from image paths\n",
    "    def convert_images_to_filename(image_list):\n",
    "        filenames = []\n",
    "        for img in image_list:\n",
    "            filename = os.path.basename(img.filename)\n",
    "            filenames.append(filename)\n",
    "        return filenames\n",
    "    \n",
    "    # Function to convert labels to one-hot encoding\n",
    "    def convert_labels_to_one_hot(label_list, label_mapping):\n",
    "        numerical_labels = [label_mapping[label] for label in label_list]\n",
    "        num_classes = len(label_mapping)\n",
    "        one_hot_labels = to_categorical(numerical_labels, num_classes=num_classes)\n",
    "        return one_hot_labels\n",
    "    \n",
    "    # Load images using PIL\n",
    "    list_pillow_TESTSET = load_images_from_directory_PIL(directory)\n",
    "    \n",
    "    # Convert the list of PIL images to pixel arrays\n",
    "    pixel_arrays_TESTSET = convert_images_to_arrays(list_pillow_TESTSET)\n",
    "    \n",
    "    # Get the names of the images\n",
    "    names_TESTSET = convert_images_to_filename(list_pillow_TESTSET)\n",
    "    \n",
    "    # Extract labels from filenames\n",
    "    ALStype_TESTSET = [name.split('_')[0] for name in names_TESTSET]\n",
    "    \n",
    "    # Update the labels based on the mapping\n",
    "    ALStype_Num_TESTSET = [label_mapping[label] for label in ALStype_TESTSET]\n",
    "    \n",
    "    # Create one-hot encoded labels\n",
    "    one_hot_labels_TESTSET = convert_labels_to_one_hot(ALStype_TESTSET, label_mapping)\n",
    "    \n",
    "    # Build the dictionary\n",
    "    dict_TESTSET = {'Name': names_TESTSET, 'ALStype': ALStype_TESTSET, 'PixelArrays': pixel_arrays_TESTSET, 'ALStype_Num': ALStype_Num_TESTSET, 'one_hot_labels': one_hot_labels_TESTSET}\n",
    "    \n",
    "    return dict_TESTSET\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"3CH\": 0,\n",
    "    \"3CTL\": 1,\n",
    "    \"3CN\": 2,\n",
    "    \"3CL\": 3,\n",
    "    \"4C\": 4,\n",
    "    \"4CL\": 5,\n",
    "    \"4CTL\": 6\n",
    "}\n",
    "\n",
    "dict_TESTSET = prepare_testset(path_TESTSET, label_mapping)\n",
    "\n",
    "# Variables for testing the model\n",
    "X_test = np.array(dict_TESTSET['PixelArrays'])\n",
    "y_test = np.array(dict_TESTSET['one_hot_labels'])\n",
    "y_test_ALStype_Num = np.array(dict_TESTSET['ALStype_Num'])\n",
    "\n",
    "# Print the one-hot encoded labels\n",
    "print(dict_TESTSET[\"one_hot_labels\"])\n",
    "\n",
    "\n",
    "def test_model(loaded_best_model, X_test, y_test):\n",
    "    # Assuming you have a dataset (X_test) and its corresponding true labels (y_test)\n",
    "    y_pred = loaded_best_model.predict(X_test)\n",
    "\n",
    "    # Assuming y_true is one-hot encoded, you can obtain the predicted class labels\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)  # Assuming y_true is one-hot encoded\n",
    "\n",
    "    # Compute Precision, Recall, and F1-score\n",
    "    precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "    recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "    f1_score_val = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "    # Compute ROC-AUC for each class\n",
    "    roc_auc = roc_auc_score(y_test, y_pred, average='macro')  # Assuming you have multi-class labels\n",
    "\n",
    "    # Print the classification report which includes precision, recall, and f1-score\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true_classes, y_pred_classes))\n",
    "\n",
    "    # Print Precision, Recall, and F1-score\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-Score:\", f1_score_val)\n",
    "\n",
    "    # Print ROC-AUC score\n",
    "    print(\"ROC-AUC (Macro):\", roc_auc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_model(best_IncV3, X_test, y_test)) \n",
    "print(test_model(best_Xcep, X_test, y_test)) \n",
    "print(test_model(best_ResNet50, X_test, y_test)) \n",
    "print(test_model(best_ResNet101, X_test, y_test)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputf2.10py3.8",
   "language": "python",
   "name": "gputf2.10py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
